# -*- coding: utf-8 -*-
"""Automated_Book_Publishing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fvsuDZvZ9sWBbb1qVUNRByhg8-3r-fPb
"""

# Install BeautifulSoup for parsing
!pip install beautifulsoup4 requests

"""# **STEP 1: Web Scraping & Screenshot**

We'll fetch the chapter content and screenshot from: https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1
"""

#Step 1.2: Scrape the Chapter Text
import requests
from bs4 import BeautifulSoup

def fetch_chapter_text(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")

    content_div = soup.find("div", class_="mw-parser-output")
    paragraphs = content_div.find_all(["p", "h2", "h3"])

    chapter_text = "\n".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))

    return chapter_text

# URL of Chapter 1
url = "https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1"
chapter_text = fetch_chapter_text(url)

# Save to file
with open("chapter1_raw.txt", "w", encoding="utf-8") as f:
    f.write(chapter_text)

# Show preview
print(chapter_text[:1000])  # print first 1000 characters

!pip install transformers sentencepiece

"""# **STEP 2: AI Writer**"""

#STEP 2: AI Writer (Chapter "Spinning")
#Step 2.2: Load FLAN-T5 and Define Rewrite Function

from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

# Load FLAN-T5 model from Hugging Face
model_name = "google/flan-t5-large"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Create pipeline
rewrite_pipe = pipeline("text2text-generation", model=model, tokenizer=tokenizer)

# Rewrite function
def rewrite_chapter(text):
    prompt = f"Rewrite this in a vivid and engaging modern style:\n\n{text}"
    result = rewrite_pipe(prompt, max_length=512, do_sample=True, top_p=0.9, temperature=0.8)[0]['generated_text']
    return result

#Step 2.3: Load the Raw Chapter & Rewrite It
# Load raw text from Step 1
with open("chapter1_raw.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()

# Limit input to ~1000 characters for this model (or batch in future)
input_text = raw_text[:1000]

# Rewrite it
rewritten_text = rewrite_chapter(input_text)

# Save the rewritten text
with open("chapter1_spun.txt", "w", encoding="utf-8") as f:
    f.write(rewritten_text)

# Show result
print(" Rewritten Chapter Sample:\n")
print(rewritten_text)

#Download AI-rewritten content
from google.colab import files
files.download("chapter1_spun.txt")

"""# **STEP 3: AI Reviewer**"""

#Step 3.1: Review Function using FLAN-T5
def review_text(text):
    prompt = f"Please review the following rewritten text for grammar, clarity, and style. Provide constructive feedback:\n\n{text}"
    review = rewrite_pipe(prompt, max_length=512, do_sample=True, top_p=0.9, temperature=0.7)[0]['generated_text']
    return review

#Step 3.2: Load the Rewritten Text and Run the Review
# Load rewritten text
with open("chapter1_spun.txt", "r", encoding="utf-8") as f:
    spun_text = f.read()

# Get AI feedback
review = review_text(spun_text)

# Save feedback
with open("chapter1_review.txt", "w", encoding="utf-8") as f:
    f.write(review)

# Display feedback
print(" AI Review Feedback:\n")
print(review)

from google.colab import files
files.download("chapter1_review.txt")

"""# **STEP 4: Human-in-the-Loop Editing**"""

#Step 4.1: Display Rewritten Chapter + Input Feedback
# Show the AI-spun text for reference
with open("chapter1_spun.txt", "r", encoding="utf-8") as f:
    spun_text = f.read()

print(" Rewritten Chapter (AI):\n")
print(spun_text[:1000])  # Display part of it for preview

from IPython.display import display
import ipywidgets as widgets

feedback = widgets.Textarea(
    value='',
    placeholder='Type your suggestions or rewrite here...',
    description=' Human Feedback:',
    layout=widgets.Layout(width='100%', height='150px'),
    style={'description_width': 'initial'}
)

display(feedback)

""""You can improve clarity in the second paragraph. Some sentences feel too long or complex." type this as your feedback"""

#Step 4.2: Save Your Feedback
with open("chapter1_human_feedback.txt", "w", encoding="utf-8") as f:
    f.write(feedback.value)

print("✅ Human feedback saved to chapter1_human_feedback.txt")

from google.colab import files
files.download("chapter1_human_feedback.txt")

"""# **STEP 5: Versioning with ChromaDB in Colab**"""

!pip install chromadb

#Step 5.2: Load All Versions from Files
# Load all four versions
def load_version(filename):
    with open(filename, "r", encoding="utf-8") as f:
        return f.read()

version_data = {
    "raw": load_version("chapter1_raw.txt"),
    "spun": load_version("chapter1_spun.txt"),
    "review": load_version("chapter1_review.txt"),
    "human": load_version("chapter1_human_feedback.txt")
}

#Step 5.3: Store into ChromaDB
import chromadb
from chromadb.utils import embedding_functions

# Create a persistent Chroma client (stored in-memory in Colab)
chroma_client = chromadb.Client()

# Create collection
collection = chroma_client.get_or_create_collection("book_chapter_versions")

# Add all versions
for key, content in version_data.items():
    collection.add(
        documents=[content],
        ids=[f"chapter1_{key}"],
        metadatas=[{
            "chapter": 1,
            "version": key,
            "status": "final" if key == "human" else "intermediate"
        }]
    )

print(" All chapter versions stored successfully in ChromaDB!")

#See What's in ChromaDB
results = collection.get(include=["documents", "metadatas"])
for doc_id, meta, doc in zip(results["ids"], results["metadatas"], results["documents"]):
    print(f" {doc_id} — Metadata: {meta} — Document: {doc[:100]}...") # Print first 100 characters

"""# **Step 6: RL Search Algorithm: For consistent data retrieval.**"""

#Step 6.1: Define Search Query + Perform Smart Retrieval
# Simulate a smart RL search: Find best version for a purpose
def smart_query(query, collection):
    result = collection.query(
        query_texts=[query],
        n_results=3,
        include=["documents", "metadatas"] # Removed 'ids' from include
    )
    return result

# Step 6.2: Run a Smart Search Query
query = "Most human-edited and polished version of chapter 1"
results = smart_query(query, collection)

# Display top result
print(" Top Result:\n")
print(f" ID: {results['ids'][0][0]}")
print(f" Metadata: {results['metadatas'][0][0]}")
print("\n Document Content Preview:\n")
print(results["documents"][0][0][:1000])  # Preview first 1000 characters